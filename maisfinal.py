# -*- coding: utf-8 -*-
"""MaisFinal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kWCLwqgCV3ekrgNt3k-WyIJ97TC7A03q
"""

import pandas as pd
import numpy as np
import re
from collections import Counter

df = pd.read_csv("https://raw.githubusercontent.com/fiaosborne/MaisFinal/main/Language_Detection.csv")

text = df["Text"].tolist()
for i in (range(len(text))):
  text[i] = str(text[i])
language = df["Language"].tolist()

print(language)

def clean(txt):
  #txt = txt.lower()
  txt = txt.lower()
  txt = re.sub('<.*?>','',txt)
  txt = re.sub('\[.*?\]','',txt)
  txt = re.sub('\(.*?\)','',txt)
  txt = re.sub(r'[0-9]','',txt)
  txt = re.sub(r'[!.,\'\"-]','', txt)
  return txt

txt_data = []
for line in text:
  txt_data.append(clean(line))

print(txt_data)

def lang_to_int(lang):
    if lang == "English":
      return 1
    elif lang == "Malayalam":
      return 2
    elif lang == "Hindi":
      return 3
    elif lang == "Tamil":
      return 4
    elif lang ==  "Kannada":
      return 5
    elif lang ==  "French":
      return 6
    elif lang ==  "Spanish":
      return 7
    elif lang ==  "Portugeese":
      return 8
    elif lang ==  "Italian":
      return 9
    elif lang ==  "Russian":
      return 10
    elif lang ==  "Sweedish":
      return 11
    elif lang ==  "Dutch":
      return 12
    elif lang ==  "Arabic":
      return 13
    elif lang ==  "Turkish":
      return 14
    elif lang ==  "German":
      return 15
    elif lang ==  "Danish":
      return 16
    elif lang ==  "Greek":
      return 17

for i in (range(len(language))):
  language[i] = lang_to_int(language[i])

print(language)

count = [0]*17
for i in language:
  count[i-1]+=1

print(count)

txt_test = []
lang_test = []
txt_train = []
lang_train = []
i = 0
while i < len(txt_data):
  if i % 5 == 0:
    txt_test.append(txt_data[i])
    lang_test.append(language[i])
  else:
    txt_train.append(txt_data[i])
    lang_train.append(language[i])
  
  i+=1

print(txt_test)

def get_vocab(text_list,vocab_size):

  text = [j for i in text_list for j in i.split()]

  r = Counter(text)
  vocab = {}
  common = r.most_common(vocab_size)
  for i in range(len(common)):
    vocab[common[i][0]]=i


  return vocab

vocab_size = 10000
vocab = get_vocab(txt_test,vocab_size)

print(len(vocab))
print(vocab)

def vectorize(txt_str,vocab):

  txt = txt_str.split()
  txt_dict = dict.fromkeys(txt,0)

  t = [0]*len(vocab)
  for key in txt_dict.keys():
    if key in vocab:
      index = vocab[key]
      t[index] = 1
  return t

vector = vectorize("ну вы можете просто ответить не могу жаловаться все действительно круто",vocab)
print(vector)
print(sum(vector))

txt_train_vect = []

for i in (range(len(txt_train))):
  txt_train_vect.append(vectorize(txt_train[i],vocab))

txt_test_vect = []

for i in (range(len(txt_test))):
  txt_test_vect.append(vectorize(txt_test[i],vocab))

WRONG

Pr_lang = [0]*17

for i in (range(len(Pr_lang))):
  Pr_lang[i] = lang_train.count(i+1)/len(lang_train)

counter = [[0]*len(vocab)]*17
for i in (range(len(vocab))):
  for j in range(len(lang_train)):
    if lang_train[j] == 1:
      if txt_train_vect[j][i] == 1:
        counter[0][i] += 1
    elif lang_train[j] == 2:
      if txt_train_vect[j][i] == 1:
        counter[1][i] += 1
    elif lang_train[j] == 3:
      if txt_train_vect[j][i] == 1:
        counter[2][i] += 1
    elif lang_train[j] == 4:
      if txt_train_vect[j][i] == 1:
        counter[3][i] += 1
    elif lang_train[j] == 5:
      if txt_train_vect[j][i] == 1:
        counter[4][i] += 1
    elif lang_train[j] == 6:
      if txt_train_vect[j][i] == 1:
        counter[5][i] += 1
    elif lang_train[j] == 7:
      if txt_train_vect[j][i] == 1:
        counter[6][i] += 1
    elif lang_train[j] == 8:
      if txt_train_vect[j][i] == 1:
        counter[7][i] += 1
    elif lang_train[j] == 9:
      if txt_train_vect[j][i] == 1:
        counter[8][i] += 1
    elif lang_train[j] == 10:
      if txt_train_vect[j][i] == 1:
        counter[9][i] += 1
    elif lang_train[j] == 11:
      if txt_train_vect[j][i] == 1:
        counter[10][i] += 1
    elif lang_train[j] == 12:
      if txt_train_vect[j][i] == 1:
        counter[11][i] += 1
    elif lang_train[j] == 13:
      if txt_train_vect[j][i] == 1:
        counter[12][i] += 1
    elif lang_train[j] == 14:
      if txt_train_vect[j][i] == 1:
        counter[13][i] += 1
    elif lang_train[j] == 15:
      if txt_train_vect[j][i] == 1:
        counter[14][i] += 1
    elif lang_train[j] == 16:
      if txt_train_vect[j][i] == 1:
        counter[15][i] += 1
    elif lang_train[j] == 17:
      if txt_train_vect[j][i] == 1:
        counter[16][i] += 1
    
print(counter)

Pr_txt_en = [0]*len(vocab)
Pr_txt_ma = [0]*len(vocab)
Pr_txt_hi = [0]*len(vocab)
Pr_txt_ta = [0]*len(vocab)
Pr_txt_ka = [0]*len(vocab)
Pr_txt_fr = [0]*len(vocab)
Pr_txt_sp = [0]*len(vocab)
Pr_txt_po = [0]*len(vocab)
Pr_txt_it = [0]*len(vocab)
Pr_txt_ru = [0]*len(vocab)
Pr_txt_sw = [0]*len(vocab)
Pr_txt_du = [0]*len(vocab)
Pr_txt_ar = [0]*len(vocab)
Pr_txt_tu = [0]*len(vocab)
Pr_txt_ge = [0]*len(vocab)
Pr_txt_da = [0]*len(vocab)
Pr_txt_gr = [0]*len(vocab)

for i in (range(len(vocab))):
  for j in range(len(lang_train)):
    if lang_train[j] == 1:
      if txt_train_vect[j][i] == 1:
        Pr_txt_en[i] += 1
    elif lang_train[j] == 2:
      if txt_train_vect[j][i] == 1:
        Pr_txt_ma[i] += 1
    elif lang_train[j] == 3:
      if txt_train_vect[j][i] == 1:
        Pr_txt_hi[i] += 1
    elif lang_train[j] == 4:
      if txt_train_vect[j][i] == 1:
        Pr_txt_ta[i] += 1
    elif lang_train[j] == 5:
      if txt_train_vect[j][i] == 1:
        Pr_txt_ka[i] += 1
    elif lang_train[j] == 6:
      if txt_train_vect[j][i] == 1:
        Pr_txt_fr[i] += 1
    elif lang_train[j] == 7:
      if txt_train_vect[j][i] == 1:
        Pr_txt_sp[i] += 1
    elif lang_train[j] == 8:
      if txt_train_vect[j][i] == 1:
        Pr_txt_po[i] += 1
    elif lang_train[j] == 9:
      if txt_train_vect[j][i] == 1:
        Pr_txt_it[i] += 1
    elif lang_train[j] == 10:
      if txt_train_vect[j][i] == 1:
        Pr_txt_ru[i] += 1
    elif lang_train[j] == 11:
      if txt_train_vect[j][i] == 1:
        Pr_txt_sw[i] += 1
    elif lang_train[j] == 12:
      if txt_train_vect[j][i] == 1:
        Pr_txt_du[i] += 1
    elif lang_train[j] == 13:
      if txt_train_vect[j][i] == 1:
        Pr_txt_ar[i] += 1
    elif lang_train[j] == 14:
      if txt_train_vect[j][i] == 1:
        Pr_txt_tu[i] += 1
    elif lang_train[j] == 15:
      if txt_train_vect[j][i] == 1:
        Pr_txt_ge[i] += 1
    elif lang_train[j] == 16:
      if txt_train_vect[j][i] == 1:
        Pr_txt_da[i] += 1
    elif lang_train[j] == 17:
      if txt_train_vect[j][i] == 1:
        Pr_txt_gr[i] += 1

Pr_lang = [0]*17

for i in (range(len(Pr_lang))):
  Pr_lang[i] = lang_train.count(i+1)/len(lang_train)

print(Pr_lang)

Pr_x = [[0]*len(vocab)]*17
for i in (range(len(vocab))):
  Pr_txt_en[i] =  Pr_txt_en[i]/lang_train.count(1)
  Pr_txt_ma[i] =  Pr_txt_ma[i]/lang_train.count(2)
  Pr_txt_hi[i] =  Pr_txt_hi[i]/lang_train.count(3)
  Pr_txt_ta[i] =  Pr_txt_ta[i]/lang_train.count(4)
  Pr_txt_ka[i] =  Pr_txt_ka[i]/lang_train.count(5)
  Pr_txt_fr[i] =  Pr_txt_fr[i]/lang_train.count(6)
  Pr_txt_sp[i] =  Pr_txt_sp[i]/lang_train.count(7)
  Pr_txt_po[i] =  Pr_txt_po[i]/lang_train.count(8)
  Pr_txt_it[i] =  Pr_txt_it[i]/lang_train.count(9)
  Pr_txt_ru[i] =  Pr_txt_ru[i]/lang_train.count(10)
  Pr_txt_sw[i] =  Pr_txt_sw[i]/lang_train.count(11)
  Pr_txt_du[i] =  Pr_txt_du[i]/lang_train.count(12)
  Pr_txt_ar[i] =  Pr_txt_ar[i]/lang_train.count(13)
  Pr_txt_tu[i] =  Pr_txt_tu[i]/lang_train.count(14)
  Pr_txt_ge[i] =  Pr_txt_ge[i]/lang_train.count(15)
  Pr_txt_da[i] =  Pr_txt_da[i]/lang_train.count(16)
  Pr_txt_gr[i] =  Pr_txt_gr[i]/lang_train.count(17)

print(Pr_txt_en)

def naive_bayes(vec):

  prob = Pr_lang

  for i in (range(len(vec))):
    if vec[i] ==1:
      prob[0] = prob[0]*Pr_txt_en[i]
      prob[1] = prob[1]*Pr_txt_ma[i]
      prob[2] = prob[2]*Pr_txt_hi[i]
      prob[3] = prob[3]*Pr_txt_ta[i]
      prob[4] = prob[4]*Pr_txt_ka[i]
      prob[5] = prob[5]*Pr_txt_fr[i]
      prob[6] = prob[6]*Pr_txt_sp[i]
      prob[7] = prob[7]*Pr_txt_po[i]
      prob[8] = prob[8]*Pr_txt_it[i]
      prob[9] = prob[9]*Pr_txt_ru[i]
      prob[10] = prob[10]*Pr_txt_sw[i]
      prob[11] = prob[11]*Pr_txt_du[i]
      prob[12] = prob[12]*Pr_txt_ar[i]
      prob[13] = prob[13]*Pr_txt_tu[i]
      prob[14] = prob[14]*Pr_txt_ge[i]
      prob[15] = prob[15]*Pr_txt_da[i]
      prob[16] = prob[16]*Pr_txt_gr[i]

  print(prob)
  max = prob[0]
  ind = 0

  for i in (range(len(prob))):
    if prob[i] > max:
      max = prob[i]
      ind = i

  return ind+1

def naive_bayess(vec):

  prob_en = Pr_lang[0]
  prob_ma = Pr_lang[1]
  prob_hi = Pr_lang[2]
  prob_ta = Pr_lang[3]
  prob_ka = Pr_lang[4]
  prob_fr = Pr_lang[5]
  prob_sp = Pr_lang[6]
  prob_po = Pr_lang[7]
  prob_it = Pr_lang[8]
  prob_ru = Pr_lang[9]
  prob_sw = Pr_lang[10]
  prob_du = Pr_lang[11]
  prob_ar = Pr_lang[12]
  prob_tu = Pr_lang[13]
  prob_ge = Pr_lang[14]
  prob_da = Pr_lang[15]
  prob_gr = Pr_lang[16]

  for i in (range(len(vec))):
    if vec[i] == 1:
      prob_en = prob_en*Pr_txt_en[i]
      prob_ma = prob_ma*Pr_txt_ma[i]
      prob_hi = prob_hi*Pr_txt_hi[i]
      prob_ta = prob_ta*Pr_txt_ta[i]
      prob_ka = prob_ka*Pr_txt_ka[i]
      prob_fr = prob_fr*Pr_txt_fr[i]
      prob_sp = prob_sp*Pr_txt_sp[i]
      prob_po = prob_po*Pr_txt_po[i]
      prob_it = prob_it*Pr_txt_it[i]
      prob_ru = prob_ru*Pr_txt_ru[i]
      prob_sw = prob_sw*Pr_txt_sw[i]
      prob_du = prob_du*Pr_txt_du[i]
      prob_ar = prob_ar*Pr_txt_ar[i]
      prob_tu = prob_tu*Pr_txt_tu[i]
      prob_ge = prob_ge*Pr_txt_ge[i]
      prob_da = prob_da*Pr_txt_da[i]
      prob_gr = prob_gr*Pr_txt_gr[i]

  
  probability = [prob_en, prob_ma, prob_hi, prob_ta, prob_ka, prob_fr, prob_sp, prob_po, prob_it, prob_ru, prob_sw, prob_du, prob_ar, prob_tu, prob_ge, prob_da, prob_gr]
  
  max = probability[0]
  ind = 0
  for i in (range(len(probability))):
    if probability[i] > max:
      max = probability[i]
      ind = i

  return ind+1

naive_bayess(vectorize("hello the my name is blank",vocab))

from sklearn.metrics import accuracy_score
predictor = []

for i in (range(len(txt_test_vect))):
  predictor.append(naive_bayess(txt_test_vect[i]))

print(lang_test)
print(predictor)

accuracy = accuracy_score(lang_test,predictor,normalize=True,sample_weight=None)
print(accuracy)